<h1>Introduction</h1>

<h2>Problem Statement</h2>
<p>
Local descriptor reranking in Visual Place Recognition faces a critical challenge: while providing high accuracy, it's computationally expensive with complexity \(O(D(F) \times N(F) \times N(Q) \times N(R))\). The Attentive Patch algorithm attempted to solve this by reducing the number of descriptors needed for matching, but struggles with environmental variations, particularly in the SPED dataset.
</p>

<h2>Our Contributions</h2>
<ul>
    <li><strong>Problem Analysis:</strong> We identified specific failure modes of the Attentive Patch algorithm in challenging environments, particularly its tendency to focus on non-distinctive features.</li>
    <li><strong>Improved Anchor Selection:</strong> We developed three new anchor selection strategies that better identify distinctive scene elements.</li>
    <li><strong>Adaptive Thresholding:</strong> We introduced a dynamic threshold mechanism that adjusts based on feature importance.</li>
    <li><strong>Performance Gains:</strong> Our improvements achieved better accuracy while maintaining the speed advantages of the original algorithm.</li>
</ul>

<h1>Methods</h1>

<h2>Limitations in Existing Approach</h2>

<figure class="comparison-figure">
    <div class="image-container">
        <img src="../media/images/vpr/query_0000025.jpg" alt="Query Image">
        <img src="../media/images/vpr/ref_0000025.jpg" alt="Reference Image">
    </div>
    <figcaption>
        <em>Figure 1: SPED dataset example showing the same location under different conditions. Our method successfully matches these despite seasonal changes.</em>
    </figcaption>
</figure>

<figure class="result-figure">
    <img src="../media/images/vpr/attnPatch_wrong_pred.png" alt="Attentive Patch Wrong Prediction">
    <figcaption>
        <em>Figure 2: Original algorithm's incorrect emphasis on repetitive features.</em>
    </figcaption>
</figure>

<p>
We identified two key problems in the current Attentive Patch algorithm:
</p>
<ul>
    <li>Poor performance in identifying stable landmarks under environmental changes</li>
    <li>Over-emphasis on repetitive features like sky and road markings</li>
</ul>

<div class="solutions-section">
    <div class="solutions-text">
        <h2>Our Solutions</h2>

        <h3>1. Enhanced Anchor Selection</h3>
        <p>
        We developed three complementary strategies for selecting anchor points:
        </p>

        <h4>Grid-based Self-similarity</h4>
        <p>
        Our implementation divides images into grids and selects anchors based on local distinctiveness, ensuring better spatial distribution of feature points.
        </p>

        <h4>High-pass Filter Selection</h4>
        <p>
        This method emphasizes edges and textures, identifying features that are more likely to remain consistent across environmental changes.
        </p>

        <h4>Semantic-aware Selection</h4>
        <p>
        By applying semantic segmentation, we prioritize stable landmarks while filtering out variable elements like sky and vegetation.
        </p>

        <h3>2. Dynamic Thresholding</h3>
        <p>
        We introduced an adaptive thresholding system that:
        </p>
        <ul>
            <li>Dynamically adjusts thresholds based on feature importance</li>
            <li>Uses lower thresholds near key features for better sensitivity</li>
            <li>Applies higher thresholds in areas prone to false matches</li>
        </ul>
    </div>

    <div class="solutions-figures">
        <figure>
            <img src="../media/images/vpr/filter.png" alt="High-pass Filtering">
            <figcaption>
                <em>Figure 3: Our high-pass filter method highlighting distinctive edges and textures.</em>
            </figcaption>
        </figure>

        <figure>
            <img src="../media/images/vpr/segmentation_mask.png" alt="Segmentation Mask">
            <figcaption>
                <em>Figure 4: Our semantic segmentation approach focusing on stable landmarks.</em>
            </figcaption>
        </figure>

        <figure>
            <img src="/media/images/vpr/heatmap.png" alt="Adaptive Threshold Heatmap">
            <figcaption>
                <em>Figure 5: Our adaptive threshold mechanism in action. Brighter regions indicate higher thresholds.</em>
            </figcaption>
        </figure>
    </div>
</div>
