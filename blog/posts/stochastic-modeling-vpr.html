<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Exploring Stochastic Modeling in Visual Place Recognition</title>

    <!-- Fonts -->
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/lora/3.0.2/lora.min.css"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
      rel="stylesheet"
    />

    <!-- KaTeX Math Support -->
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/katex.min.css"
      rel="stylesheet"
    />

    <!-- Site Assets -->
    <link rel="icon" type="image/svg+xml" href="../../media/images/icon.svg" />
    <link href="/css/blog.css" rel="stylesheet" />

    <!-- KaTeX Scripts -->
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/katex.min.js"
    ></script>
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/contrib/auto-render.min.js"
    ></script>

    <!-- Custom Scripts -->
    <script defer src="/js/copy-button.js"></script>
  </head>
  <body>
    <div class="blog-post">
      <a href="../" class="back-button">
        <i class="fas fa-arrow-left"></i>Back to Blog
      </a>

      <header class="blog-post-header">
        <h1 class="blog-post-title">
          Exploring Stochastic Modeling in Visual Place Recognition
        </h1>
        <div class="blog-post-date">February 1, 2025</div>
      </header>

      <article class="blog-post-content">
        <h2>Introduction</h2>
        <p>
          You know how VAEs have this really neat trick of handling uncertainty?
          Well, after diving deep into VAEs in my previous blog post, I had this
          "wait a minute" moment. What if we could bring that same magic to
          visual place recognition (VPR)? For those who aren't familiar with
          VPR, it's basically teaching robots to recognize places they've been
          before - kind of like how you'd recognize your favorite coffee shop,
          but for machines.
        </p>
        <p>
          Now, I should probably mention upfront that this is one of those
          "failed experiment" stories. But hey, sometimes the attempts that
          don't work out teach us the most interesting lessons, right? So buckle
          up - I'm going to share my journey of trying (and ultimately failing)
          to make this work, and all the fascinating insights I gained along the
          way.
        </p>

        <h2>1. Motivation</h2>
        <p>
          Here's the thing about current VPR systems - they're a bit like that
          friend who's super confident about everything but then gets completely
          lost when things change slightly. They face some pretty real
          challenges:
        </p>
        <ul>
          <li>
            <strong>The Weather Problem:</strong> A place can look totally
            different just because it's sunny instead of rainy, or summer
            instead of winter. (Imagine trying to recognize your street when
            it's covered in snow!)
          </li>
          <li>
            <strong>The Viewpoint Problem:</strong> Move a few steps to the left
            or right, and suddenly everything looks different to our robot
            friends
          </li>
          <li>
            <strong>The "Everything Looks the Same" Problem:</strong> Try
            telling apart different Starbucks locations - that's what we call
            perceptual aliasing in fancy terms
          </li>
        </ul>
        <p>
          Looking at these challenges, I had this thought: "Hey, isn't
          uncertainty kind of the common thread here?" I mean, VAEs handle
          uncertainty beautifully by saying "we're not 100% sure about this, but
          here's our best guess and how confident we are about it." So I
          wondered - what if we could bring that same mindset to place
          recognition?
        </p>

        <h2>2. The Stochastic VPR Framework</h2>
        <h3>2.1 Traditional Approach: Contrastive Learning</h3>
        <p>
          Before diving into my stochastic approach, let's look at how VPR
          typically works. The traditional approach uses contrastive learning,
          where we train a network to map images to point embeddings in a way
          that makes similar places close together and different places far
          apart.
        </p>

        <div class="math-block">
          <p>
            Usually, we have a backbone network \(f\) that maps an image \(x\)
            to a feature vector:
          </p>
          \[f_\theta: X \rightarrow \mathbb{R}^d\]

          <p>And we train it with contrastive loss (like InfoNCE):</p>
          \[L_{cont} = -\log \frac{\exp(f(x_i)^T f(x_j)/\tau)}{\sum_{k \neq i}
          \exp(f(x_i)^T f(x_k)/\tau)}\]

          <p>
            where \((x_i, x_j)\) are images of the same place, and \(\tau\) is a
            temperature parameter.
          </p>
        </div>

        <h3>2.2 The Stochastic Approach</h3>
        <p>
          Here's where I had what I thought was a clever idea: What if each
          image of a place isn't just a point in feature space, but a sample
          from some underlying probability distribution? Think about it - a
          place under different conditions (lighting, weather, viewpoint) could
          be seen as different samples from a place-specific distribution.
        </p>

        <p>
          This approach felt promising for a couple of reasons. First, it seemed
          like a natural way to handle uncertainty. Instead of forcing every
          image to sit rigidly at a single point in feature space, I thought,
          "What if each place could be fluid, represented as a probability cloud
          that shifts slightly with lighting, weather, or viewpoint?" It's like
          saying, "I'm pretty sure this is the same place—but here's how
          confident I am."
        </p>
        <p>
          Secondly, the sampling process itself felt like a hidden bonus—kind of
          like getting free data augmentation without the extra work. Each time
          we sample from the distribution, it's as if we're seeing the place
          from a slightly different perspective, making the model naturally more
          robust to real-world variations.
        </p>

        <h3>2.3 Mathematical Formulation</h3>
        <p>
          For an input image \(x_i\), our backbone network now outputs
          distribution parameters:
        </p>
        <div class="math-block">\[f_\theta(x_i) = (\mu_i, \Sigma_i)\]</div>

        <p>This defines a latent distribution for each image:</p>
        <div class="math-block">\[q_i = \mathcal{N}(\mu_i, \Sigma_i)\]</div>

        <p>We generate features through the reparameterization trick:</p>
        <div class="math-block">
          \[\varepsilon \sim \mathcal{N}(0, I)\] \[z_i = \mu_i + \Sigma_i^{1/2}
          \varepsilon\]
        </div>

        <p>Final descriptor after pooling:</p>
        <div class="math-block">\[d_i = g(z_i)\]</div>

        <p>The training objective combines two components:</p>
        <p>1. Distribution Alignment Loss (for positive pairs):</p>
        <div class="math-block">
          \[L_{KL} = D_{KL}(q_i || q_j) + D_{KL}(q_j || q_i)\]
        </div>

        <p>2. Contrastive Learning Loss:</p>
        <div class="math-block">
          \[L_{cont} = -\log \frac{\exp(d_i^T d_j/\tau)}{\sum_{k \neq i}
          \exp(d_i^T d_k/\tau)}\]
        </div>

        <p>Total Loss:</p>
        <div class="math-block">\[L_{total} = L_{cont} + \lambda L_{KL}\]</div>

        <p>Training Objective:</p>
        <div class="math-block">
          \[\theta^* = \arg\min_\theta \mathbb{E}_{x_i, x_j \in P}[L_{total}]\]
        </div>

        <p>
          where \(P\) is the set of positive pairs (images of the same place).
        </p>

        <p>
          Note that while I used InfoNCE-style contrastive loss here, the
          framework is flexible - we could swap in other contrastive losses like
          triplet loss or circle loss. The key innovation is in the stochastic
          modeling of the features, not the specific choice of contrastive loss.
        </p>

        <h2>3. Experimental Setup</h2>

        <h3>3.1 Implementation Details</h3>
        <p>The model was implemented with the following architecture:</p>
        <ul>
          <li><strong>Backbone:</strong> ResNet50 pretrained on ImageNet</li>
          <li><strong>Embedding Dimension:</strong> 256</li>
          <li>
            <strong>Training Data:</strong> Mapillary Street-level Sequences
          </li>
          <li>
            <strong>Loss Function:</strong> InfoNCE with probabilistic
            embeddings
          </li>
        </ul>

        <div class="math-block">
          <p>The probabilistic InfoNCE loss:</p>
          $\mathcal{L} = -\mathbb{E}\left[\log \frac{\exp(\text{sim}(I,
          I^+)/\tau)}{\sum_{I^-} \exp(\text{sim}(I, I^-)/\tau)}\right]$
        </div>

        <h2>4. Initial Attempts and Observations</h2>

        <h3>4.1 The Runaway Variance Problem</h3>
        <p>
          In my first training attempts, I noticed something interesting - the
          variance kept increasing without bound. This was puzzling at first,
          but after diving deeper into the mathematics, it made sense: Unlike
          VAEs which have a reconstruction loss to constrain the variance, our
          contrastive learning setup wasn't providing enough gradient signal to
          control the variance effectively.
        </p>

        <h3>4.2 Why VAEs Work: A Natural Variance Control</h3>
        <p>
          In VAEs, the reconstruction loss has an explicit dependence on
          variance:
        </p>
        <div class="math-block">
          \[-\log N(x; \hat{x}, \sigma^2I) = \frac{1}{2\sigma^2}\|x-\hat{x}\|^2
          + \frac{D}{2}\log\sigma^2 + const\]
        </div>

        <p>This provides natural bounds:</p>
        <ul>
          <li>
            If \(\sigma^2\) gets too large: The \(\log\sigma^2\) term grows
          </li>
          <li>
            If \(\sigma^2\) gets too small: The \(\frac{1}{\sigma^2}\) term
            explodes
          </li>
        </ul>

        <h3>4.3 Single-Sample Contrastive: The Problem</h3>
        <p>
          Consider a positive pair \((x_i, x_j)\). In the standard contrastive
          setup:
        </p>

        <p>1. Sample one point from each distribution:</p>
        <div class="math-block">
          \[z_i = \mu_i + \sigma_i \epsilon_i, \quad \epsilon_i \sim N(0, I)\]
          \[z_j = \mu_j + \sigma_j \epsilon_j, \quad \epsilon_j \sim N(0, I)\]
        </div>

        <p>2. The contrastive loss sees:</p>
        <div class="math-block">
          \[\|z_i - z_j\|^2 = \| (\mu_i + \sigma_i \epsilon_i) - (\mu_j +
          \sigma_j \epsilon_j) \|^2\]
        </div>

        <p>
          3. The gradient w.r.t \(\sigma_i\) for a single dimension \(d\) is:
        </p>
        <div class="math-block">
          \[\frac{\partial \|z_i - z_j\|^2}{\partial \sigma_{i,d}} = 2(z_i -
          z_j)_d \epsilon_{i,d}\]
        </div>

        <p>This is highly problematic because:</p>
        <ul>
          <li>
            The gradient's sign depends on random noise \(\epsilon_{i,d}\)
          </li>
          <li>
            Even with large \(\sigma^2\), if \(\epsilon_i \approx \epsilon_j\),
            the gradient is small
          </li>
          <li>
            Over many batches, these random signs may partially cancel out
          </li>
        </ul>

        <h3>4.4 Multi-Sample: How It Helps</h3>
        <p>Instead of one sample, we draw \(K\) samples per image:</p>
        <div class="math-block">
          \[z_i^{(k)} = \mu_i + \sigma_i \epsilon_i^{(k)}, \quad k = 1...K\]
        </div>

        <p>The loss becomes an average over all sample pairs:</p>
        <div class="math-block">
          \[L_{multi} = \frac{1}{K^2} \sum_{k=1}^K \sum_{l=1}^K \|z_i^{(k)} -
          z_j^{(l)}\|^2\]
        </div>

        <p>Taking expectation:</p>
        <div class="math-block">
          \[\mathbb{E}[L_{multi}] = \|\mu_i - \mu_j\|^2 + \sigma_i^2 +
          \sigma_j^2\]
        </div>

        <p>
          What's fascinating is how this multi-sample approach quietly reshapes
          the learning process. Unlike the single-sample setup where variance
          feels like an unruly guest, here, variance pulls up a chair at the
          table, explicitly woven into the expected loss. No more hiding in the
          background—it's front and center.
        </p>
        <p>
          Plus, drawing multiple samples per image smooths out the noisy chaos
          of gradient updates. Imagine trying to understand a song by hearing
          just one note—that's single-sample training. But when you hear the
          whole melody, with harmonies layered in? That's what multi-sample
          training feels like. It gives the model a clearer, more consistent
          sense of how variance behaves, turning random noise into a
          well-orchestrated tune.
        </p>

        <h2>5. The Performance Trade-off</h2>

        <h3>5.1 The Batch Size Dilemma</h3>
        <p>
          While the multi-sample approach solved our variance stability issues,
          it introduced a new problem. The final model performed about 2% worse
          than a traditional deterministic approach. Why? The answer lies in how
          contrastive learning really works:
        </p>
        <ul>
          <li>
            <strong>In-batch Mining:</strong> Contrastive learning relies
            heavily on finding hard negative samples within each batch
          </li>
          <li>
            <strong>Batch Size Matters:</strong> Larger batch sizes mean more
            potential hard negatives, which typically leads to better
            performance
          </li>
          <li>
            <strong>Memory Constraints:</strong> Multiple samples per image
            means we had to reduce batch size to fit in GPU memory
          </li>
        </ul>

        <h3>5.2 The Implicit Trade-off</h3>
        <p>
          We essentially traded batch diversity for sample diversity. While our
          noised samples provided some additional positive pairs, they weren't
          as valuable as the hard negatives we lost by reducing the batch size.
          The multiple samples per image were essentially giving us "easy"
          positive pairs, while what we really needed were those challenging
          negative examples that come with larger batch sizes.
        </p>

        <h2>6. Key Insights from the Exploration</h2>
        <p>
          Stepping back from this experiment, I realized that the value wasn't
          just in the results, but in what the process revealed about the
          intersection of stochastic modeling and visual place recognition
          (VPR). This journey surfaced a few pivotal insights that reshaped my
          understanding of the problem space:
        </p>

        <p>
          First, there's an inherent tension between
          <strong>richness and efficiency</strong>. Stochastic models are great
          at capturing nuanced variability, but they come at a steep
          computational cost. The more we tried to model uncertainty, the more
          we had to wrestle with memory constraints, ultimately forcing
          trade-offs that chipped away at performance.
        </p>

        <p>
          Then came the revelation about
          <strong>what really matters in VPR</strong>. I went in thinking that
          uncertainty modeling would be the star of the show, but it turns out
          that distinguishing places that look frustratingly similar—those hard
          negatives—is the real MVP. It's less about embracing uncertainty and
          more about sharpening the system's ability to say, "No, this isn't the
          same place."
        </p>

        <p>
          Lastly, I underestimated the subtle yet powerful influence of
          <strong>batch dynamics</strong>. In contrastive learning, batch size
          isn't just a technical parameter—it fundamentally shapes how well the
          model learns. The need to reduce batch size to accommodate stochastic
          sampling inadvertently weakened the model's capacity to find
          meaningful negative examples, which turned out to be critical for
          success.
        </p>

        <h2>Conclusion</h2>
        <p>
          This wasn't the outcome I had hoped for, but it was exactly the
          outcome I needed. The experiment with stochastic modeling in VPR
          didn't yield a groundbreaking new method, but it did unravel some
          important truths about the problem itself. Sometimes, exploring an
          idea to its limits helps clarify not just what works, but why certain
          things don't.
        </p>

        <p>
          What I've learned is that VPR isn't just about handling
          uncertainty—it's about mastering distinctiveness. The ability to
          confidently differentiate between places, even under challenging
          conditions, trumps the elegance of probabilistic models when they come
          with too much computational baggage. Stochastic modeling may have its
          place, but not in the way I initially imagined.
        </p>

        <p>
          And that's the beauty of failed experiments. They don't just close
          doors—they light up the paths you might've overlooked. While I won't
          be pursuing this direction further, I leave with a deeper appreciation
          for the practical nuances of VPR and a clearer sense of where real
          innovation might lie.
        </p>

        <div
          class="citation-section"
          style="
            margin-top: 2rem;
            padding: 1rem;
            background-color: #f4f4f4;
            border-radius: 4px;
          "
        >
          <h2
            style="
              font-family: &quot;Lora&quot;, serif;
              font-size: 1.5rem;
              margin-bottom: 0.5rem;
              color: #222;
            "
          >
            Citation
          </h2>
          <p
            style="
              font-family: &quot;JetBrains Mono&quot;, monospace;
              font-size: 0.9rem;
              color: #333;
            "
          >
            Please cite this work as:
          </p>

          <pre
            style="
              background-color: #fff;
              padding: 0.75rem;
              border: 1px solid #ccc;
              border-radius: 4px;
              font-family: &quot;Fira Code&quot;, monospace;
              font-size: 0.85rem;
              overflow-x: auto;
            "
          >
@misc{stochastic-modeling-vpr,
  author    = {Tianrun Hu},
  title     = {Exploring Stochastic Modeling in Visual Place Recognition},
  year      = {2025},
  publisher = {GitHub},
  url       = {https://h-tr.github.io/blog/posts/stochastic-modeling-vpr.html}
  </pre
          >
        </div>
      </article>
    </div>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            { left: "$", right: "$", display: true },
            { left: "\\[", right: "\\]", display: true },
            { left: "\\(", right: "\\)", display: false },
            { left: "$", right: "$", display: false },
          ],
          throwOnError: false,
        });
        
        // Simple fix to make math size match text size
        document.head.insertAdjacentHTML('beforeend', 
          '<style>.katex { font-size: 1em; }</style>'
        );
      });
    </script>
    <!-- Blog styling and spacing script -->
    <script src="/js/blog.js"></script>
  </body>
</html>
