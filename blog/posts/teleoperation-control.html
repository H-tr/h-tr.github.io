<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Building Stable and Consistent Robot Control for Learning</title>

    <!-- Fonts -->
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/lora/3.0.2/lora.min.css"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css2?family=Fira+Code:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
      rel="stylesheet"
    />

    <!-- Code Highlighting -->
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css"
      rel="stylesheet"
    />

    <!-- KaTeX Math Support -->
    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/katex.min.css"
      rel="stylesheet"
    />

    <!-- Site Assets -->
    <link rel="icon" type="image/svg+xml" href="../../media/images/icon.svg" />
    <link href="../../css/blog.css" rel="stylesheet" />

    <!-- Code Highlighting Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <!-- KaTeX Scripts -->
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/katex.min.js"
    ></script>
    <script
      defer
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.3/contrib/auto-render.min.js"
    ></script>

    <!-- Custom Scripts -->
    <script defer src="/js/copy-button.js"></script>
  </head>
  <body>
    <div class="blog-post">
      <a href="../" class="back-button">
        <i class="fas fa-arrow-left"></i>Back to Blog
      </a>

      <header class="blog-post-header">
        <h1 class="blog-post-title">
          Building Stable and Consistent Robot Control for Learning
        </h1>
        <div class="blog-post-date">December 23, 2024</div>
      </header>

      <article class="blog-post-content">
        <h2>Introduction</h2>
        <p>
          In robotics, the quality of data-gathering pipelines directly impacts
          the performance of downstream learning algorithms. Whether training
          Diffusion Policies, Action Conditional Transformations (ACT), or
          reinforcement learning models, smooth and consistent control data is
          essential.
        </p>
        <p>
          This blog presents a control framework designed to provide stable and
          high-quality data for learning. By combining
          <strong>velocity control</strong>,
          <strong>delta pose representations</strong>, and
          <strong>null-space optimization</strong>, the system ensures
          consistent and noise-free data collection, enabling effective training
          for complex robotics tasks.
        </p>

        <h2>
          1. Choosing the Right Control Method: Position vs. Velocity Control
          for Robots
        </h2>
        <p>
          When designing robotic systems, the choice of control method
          significantly impacts motion quality and task execution. Stability and
          smoothness are paramount considerations, as they directly affect both
          the robot's performance and the reliability of data collection for
          learning algorithms. Velocity-based control often provides superior
          stability compared to position control, especially in scenarios
          requiring fluid motion and precise interaction with the environment.
          This advantage stems from velocity control's inherent ability to
          maintain smooth transitions and reduce abrupt movements that could
          introduce unwanted oscillations or jerky behavior. For robotics
          applications where consistent, predictable motion is essential - such
          as in collaborative robots or precision manufacturing - the smoother
          response characteristics of velocity control can lead to more reliable
          operation and better data quality for machine learning
          implementations.
        </p>

        <h3>1.1 Position Control: Understanding Sources of Instability</h3>
        <p>
          Position control in robotics typically employs PD
          (Proportional-Derivative) control, where the controller calculates
          position adjustments based on current state and desired velocity.
          However, inherent forward kinematics estimation errors can lead to
          instability, particularly at high control frequencies. The control
          process can be described as follows:
        </p>

        <div class="math-block">
          <div class="equation">
            $\Delta \mathbf{x}(t) = \mathbf{K}_p(\mathbf{x}_{\text{des}} -
            \mathbf{x}_{\text{cur}}) +
            \mathbf{K}_d(\dot{\mathbf{x}}_{\text{des}} -
            \dot{\mathbf{x}}_{\text{cur}})$
          </div>

          <div class="equation">
            $\mathbf{x}_{\text{next}} = \mathbf{x}_{\text{cur}} + \Delta
            \mathbf{x}(t)$
          </div>

          <div class="equation">
            $\mathbf{x}_{\text{actual}} = FK(\mathbf{q}) =
            \mathbf{x}_{\text{estimated}} \pm \epsilon$
          </div>

          <p>where:</p>
          <ul>
            <li>\(\Delta \mathbf{x}(t)\): Computed position adjustment</li>
            <li>\(\mathbf{K}_p\): Proportional gain matrix</li>
            <li>\(\mathbf{K}_d\): Derivative gain matrix</li>
            <li>\(\mathbf{x}_{\text{des}}\): Desired position</li>
            <li>\(\mathbf{x}_{\text{cur}}\): Current position</li>
            <li>
              \(\dot{\mathbf{x}}_{\text{des}}, \dot{\mathbf{x}}_{\text{cur}}\):
              Desired and current velocities
            </li>
            <li>\(FK(\mathbf{q})\): Forward kinematics function</li>
            <li>\(\epsilon\): Forward kinematics estimation error</li>
          </ul>
        </div>

        <p>
          The instability arises from the continuous accumulation of forward
          kinematics errors. At each control cycle (typically 100-200Hz), the
          controller computes a position adjustment \(\Delta \mathbf{x}(t)\)
          based on the estimated current position. However, since
          \(\mathbf{x}_{\text{actual}}\) always differs from
          \(\mathbf{x}_{\text{estimated}}\) by some error \(\epsilon\), the
          controller perpetually tries to correct for this difference. This
          leads to a cascading effect where:
        </p>

        <div class="math-block">
          <div class="equation">
            $\mathbf{x}_{\text{error}}(t+1) = \mathbf{x}_{\text{error}}(t) \pm
            \epsilon_{\text{new}}$
          </div>
        </div>

        <p>
          At high control frequencies, these accumulated errors manifest as
          oscillations, as the controller continuously overcompensates for
          estimation errors. The higher the control frequency, the more rapid
          these oscillations become, potentially leading to significant
          instability in the system.
        </p>

        <h3>1.2 Velocity Control: A More Stable Approach</h3>
        <p>
          Velocity control achieves smoother motion by directly regulating the
          rate of change rather than absolute position. The key difference is
          that velocity control uses the instantaneous motion state, which is
          less sensitive to accumulated forward kinematics errors. The control
          law can be expressed as:
        </p>
        <div class="math-block">
          <div class="equation">
            $\mathbf{v}_{\text{cmd}}(t) = \mathbf{K}_p \left(
            \mathbf{x}_{\text{des}} - \mathbf{x}_{\text{cur}} \right) +
            \mathbf{K}_d \left( \dot{\mathbf{x}}_{\text{des}} -
            \dot{\mathbf{x}}_{\text{cur}} \right)$
          </div>
          <div class="equation">
            $\mathbf{x}_{\text{next}} = \int_{t}^{t+\Delta t}
            \mathbf{v}_{\text{cmd}}(\tau) d\tau + \mathbf{x}_{\text{cur}}$
          </div>

          <p>where:</p>
          <ul>
            <li>\(\mathbf{v}_{\text{cmd}}(t)\): Commanded velocity</li>
            <li>\(\mathbf{K}_p\): Position gain matrix (for correction)</li>
            <li>\(\mathbf{K}_d\): Velocity gain matrix</li>
            <li>\(\Delta t\): Control cycle time interval</li>
          </ul>
        </div>

        <p>
          The stability advantage of velocity control comes from three key
          factors:
        </p>

        <p>
          1. Integration Effect: Since the position is achieved through velocity
          integration (\(\int \mathbf{v}_{\text{cmd}}(\tau) d\tau\)), the system
          naturally smooths out high-frequency disturbances. Even if there are
          forward kinematics errors \(\epsilon\), they don't accumulate in the
          same way as position control:
        </p>

        <div class="math-block">
          <div class="equation">
            $\epsilon_{\text{velocity}} =
            \frac{d}{dt}(\epsilon_{\text{position}})$
          </div>
        </div>

        <p>
          2. Error Damping: When using velocity control, any instantaneous error
          in position estimation affects only the current velocity command,
          rather than creating a direct position adjustment. This means that
          estimation errors result in velocity adjustments that are inherently
          bounded by the integration process:
        </p>

        <div class="math-block">
          <div class="equation">
            $\|\mathbf{x}_{\text{error}}(t)\| \leq \int_{0}^{t}
            \|\mathbf{v}_{\text{error}}(\tau)\| d\tau$
          </div>
        </div>

        <p>
          3. Natural Motion Constraints: Velocity control inherently respects
          the physical limitations of the robot's motion capabilities. Even with
          aggressive position error corrections, the commanded velocities remain
          within achievable limits, preventing the rapid oscillations seen in
          position control.
        </p>

        <h2>2. Delta Pose Representations in Teleoperation and Learning</h2>
        <p>
          Our teleoperation and data gathering framework employs two distinct
          types of delta poses:
        </p>
        <ul>
          <li>
            <strong>Teleoperation Delta Poses:</strong> Ensure consistency and
            frame independence when mapping VR controller movements to robot
            actions
          </li>
          <li>
            <strong>Learning Delta Poses:</strong> Serve as the action space for
            learning algorithms, enabling better mapping between observations
            and actions in the robot's base frame
          </li>
        </ul>

        <p>Now let's examine each type in detail.</p>

        <h3>2.1 Delta Pose in VR Controller Frame and Frame Transformation</h3>
        <p>
          When teleoperating the robot using a VR controller, we need to map the
          controller's motion to the robot's end-effector. The VR controller's
          pose is tracked in the VR headset's coordinate frame, typically with
          z-up convention, while the robot's end-effector pose is defined in the
          robot base frame, often using z-up or z-forward conventions depending
          on the manufacturer. This mapping involves careful transformation
          between these coordinate frames to preserve the operator's intended
          motion.
        </p>

        <div
          style="
            display: flex;
            justify-content: space-between;
            margin: 20px 0;
            align-items: center;
          "
        >
          <figure style="width: 48%; margin: 0; text-align: center">
            <img
              src="/media/images/blog/teleoperation/robot-end-effector.png"
              alt="Robot end-effector coordinate frame"
              style="width: 100%; height: auto"
            />
            <figcaption
              style="
                margin-top: 10px;
                font-style: italic;
                color: #666;
                text-align: center;
              "
            >
              Figure 1: Robot end-effector
            </figcaption>
          </figure>
          <figure style="width: 48%; margin: 0; text-align: center">
            <img
              src="/media/images/blog/teleoperation/vr-controller.png"
              alt="VR controller coordinate frame"
              style="width: 100%; height: auto"
            />
            <figcaption
              style="
                margin-top: 10px;
                font-style: italic;
                color: #666;
                text-align: center;
              "
            >
              Figure 2: VR controller
            </figcaption>
          </figure>
        </div>

        <p>
          The delta pose represents the relative pose change between consecutive
          timesteps in a <strong>frame's local coordinate system</strong>. By
          working with delta poses rather than absolute poses, we free the
          operator from needing to synchronize their hand position with the
          robot's current state. Furthermore, expressing the delta pose in the
          frame's own coordinate system makes our approach independent of both
          the VR system's and robot's base frames, enabling flexible positioning
          of both systems.
        </p>

        <div class="math-block">
          <h4>Delta Pose Computation:</h4>
          <p>
            First, we compute the delta pose in the VR controller frame between
            timesteps t-1 and t:
          </p>
          $ \Delta T_t^c = \left( T_{t-1}^c \right)^{-1} T_t^c $

          <p>
            This transformation matrix can be decomposed into rotation and
            translation components:
          </p>
          $ \Delta T_t^c = \begin{bmatrix} \Delta R_t^c & \Delta p_t^c \\ 0 & 1
          \end{bmatrix} $
        </div>

        <div class="math-block">
          <h4>Frame Transformation:</h4>
          <p>
            To transform this delta pose to the end-effector frame, we use a
            fixed transformation matrix \(R_{ve}\) that accounts for the
            difference in coordinate conventions between the VR controller and
            robot end-effector frames:
          </p>

          $ \Delta R_t^e = R_{ve} \Delta R_t^c R_{ve}^T $ $ \Delta p_t^e =
          R_{ve} \Delta p_t^c $
        </div>

        <p>
          This formulation provides three significant advantages that make it
          particularly suitable for practical robotic teleoperation:
        </p>

        <p>
          First, it enables <strong>asynchronous operation</strong> by tracking
          relative changes rather than absolute positions. In traditional
          teleoperation systems, operators must carefully align their initial
          hand position with the robot's current end-effector pose. Our
          delta-pose approach eliminates this requirement - operators can begin
          from any comfortable position, and the system will track their
          relative motions, significantly reducing setup time and operator
          fatigue.
        </p>

        <p>
          Second, the <strong>frame independence</strong> property of delta
          poses allows arbitrary positioning of both the VR system and robot.
          Since the motion is computed relative to the controller's own frame
          rather than any global coordinate system, the VR headset can be placed
          anywhere in the workspace without affecting the control mapping. This
          also makes the system robust to tracking drift in the VR system, as
          small errors in absolute position tracking don't accumulate in the
          relative motion calculations.
        </p>

        <p>
          Third, by encoding the coordinate convention differences in
          \(R_{ve}\), this approach provides strong
          <strong>cross-embodiment compatibility</strong>. The transformation
          matrix \(R_{ve}\) serves as a simple interface between different robot
          platforms, only accounting for fundamental differences in coordinate
          conventions (such as z-up versus z-forward). This means the same VR
          control system can be rapidly deployed across different robot
          platforms by simply updating \(R_{ve}\), from industrial arms to
          mobile manipulators.
        </p>

        <p>
          Together, these properties - asynchronous operation, frame
          independence, and cross-embodiment compatibility - create a robust and
          flexible teleoperation framework suitable for diverse real-world
          applications.
        </p>

        <h3>2.2 Base Frame Delta Pose for Learning</h3>
        <p>
          For learning purposes, we represent delta poses in the robot's base
          frame rather than the end-effector frame used in teleoperation. This
          choice provides better consistency for learning algorithms and handles
          real-world robotic limitations more effectively. The base frame
          representation helps address several key challenges in learning from
          teleoperation data.
        </p>

        <div class="math-block">
          <h4>Base Frame Computation:</h4>
          <p>Given two consecutive end-effector poses in the base frame:</p>
          $ T_t^b = \begin{bmatrix} R_t^b & p_t^b \\ 0 & 1 \end{bmatrix}, \quad
          T_{t-1}^b = \begin{bmatrix} R_{t-1}^b & p_{t-1}^b \\ 0 & 1
          \end{bmatrix} $

          <p>We compute the delta pose as:</p>
          $ \Delta T_t^b = \left( T_{t-1}^b \right)^{-1} T_t^b $

          <p>Which expands to:</p>
          $ \Delta T_t^b = \begin{bmatrix} (R_{t-1}^b)^T R_t^b &
          (R_{t-1}^b)^T(p_t^b - p_{t-1}^b) \\ 0 & 1 \end{bmatrix} $
        </div>

        <p>
          Using base frame delta poses ensures consistent
          <strong>action-state relationships</strong> in the learning process.
          When using end-effector frame representation, the same action can
          result in different base-frame movements depending on the current
          end-effector pose, which can confuse learning algorithms. The base
          frame representation maintains consistency: the same movement command
          will produce the same base-frame delta regardless of the current robot
          configuration.
        </p>

        <p>
          Real robotic systems often show discrepancies between commanded and
          executed movements due to PD control and physical limitations. By
          computing delta poses from actual robot state data, we capture these
          execution patterns, allowing the learning algorithm to model realistic
          robot behavior rather than ideal movements. This is crucial for
          developing policies that work well on real systems.
        </p>

        <p>
          Additionally, teleoperation systems can produce movement outliers due
          to network delays and signal processing limitations. The base frame
          representation makes these outliers easier to handle by providing
          natural physical bounds based on robot capabilities. This leads to
          more effective data normalization, which is particularly important for
          learning algorithms like diffusion policies that require
          well-normalized input data for stable training.
        </p>

        <h2>3. Null-Space Optimization</h2>
        <p>
          For redundant robots with more degrees of freedom than required for
          the task, null-space optimization enables the achievement of secondary
          objectives without interfering with the primary task of end-effector
          control. This optimization is crucial for teleoperation, where we want
          to maintain precise control while keeping the robot in favorable
          configurations.
        </p>

        <div class="math-block">
          <h4>Mathematical Framework:</h4>
          <p>
            The differential kinematics relating task and joint velocities is
            given by:
          </p>
          $ \dot{x} = J(q)\dot{q} $

          <p>
            The primary task solution using the pseudo-inverse provides minimal
            joint velocities:
          </p>
          $ \dot{q}_p = J^\dagger \dot{x} $

          <p>
            The null space projector ensures secondary tasks don't affect the
            primary task:
          </p>
          $ N = I - J^\dagger J $

          <p>
            We define a quadratic cost function for joint configuration
            optimization:
          </p>
          $ H(q) = \frac{1}{2}(q - q_{\text{home}})^T W (q - q_{\text{home}}) $

          <p>
            The complete solution combines both tasks while maintaining
            hierarchy:
          </p>
          $ \dot{q} = J^\dagger \dot{x} + N(-W(q - q_{\text{home}})) $
        </div>

        <h3>3.1 Benefits of Null-Space Optimization</h3>
        <p>
          This optimization framework provides several crucial advantages for
          teleoperation:
        </p>
        <ul>
          <li>
            <strong>Task Hierarchy:</strong> The null-space projector ensures
            that secondary objectives never interfere with end-effector control,
            maintaining precise teleoperation.
          </li>
          <li>
            <strong>Joint Limit Avoidance:</strong> Secondary tasks can keep
            joints away from their limits, ensuring smooth and safe operation
            throughout the workspace.
          </li>
          <li>
            <strong>Optimal Configuration:</strong> The robot maintains high
            manipulability by optimizing its joint configuration, improving
            dexterity during complex tasks.
          </li>
          <li>
            <strong>Efficient Motion:</strong> By minimizing joint movement
            through the home configuration cost, we reduce system wear and
            energy consumption.
          </li>
        </ul>

        <h2>Conclusion</h2>
        <p>
          By combining velocity control, delta pose representations, and
          null-space optimization, this framework provides a robust solution for
          data-gathering in robotics. The resulting data is smooth, consistent,
          and suitable for modern learning algorithms, paving the way for
          intelligent and adaptive robotic systems.
        </p>
      </article>
    </div>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
          delimiters: [
            { left: "$", right: "$", display: true },
            { left: "\\[", right: "\\]", display: true },
            { left: "\\(", right: "\\)", display: false },
            { left: "$", right: "$", display: false },
          ],
          throwOnError: false,
        });
        
        // Simple fix to make math size match text size
        document.head.insertAdjacentHTML('beforeend', 
          '<style>.katex { font-size: 1em; }</style>'
        );
      });
    </script>
    <!-- Blog styling and spacing script -->
    <script src="/js/blog.js"></script>
  </body>
</html>
